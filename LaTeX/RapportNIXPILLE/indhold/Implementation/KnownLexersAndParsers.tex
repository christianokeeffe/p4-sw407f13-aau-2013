\subsection{Known Lexers and Parsers}
\label{sec:KnownLexersAndParsers}

In this section some of the different lexer and parser generators, that are available through the internet, is described.

\subsubsection{Lexer Generators}
These programs generate a lexical analyzer also known as a scanner, that turns code into tokens which a parser uses.

\subsubsubsection{Lex:}
Files are divided into three sections separated by lines containing two percent signs. The first is the "definition section". This is where macros can be defined and where headerfiles are imported. The second is the "Rules section", where regular expressions are read in terms of C statements. The third is the "C code section" which contains C statements and functions that are copied verbatim to the generated source file. Lex is not free, but there are versions of Lex which are free such as Flex, Jflex and Jlex \citep{Lex}.

\subsubsubsection{Flex:}
Alternative to Lex \citep{Flex}.

An optional feature to flex is the REJECT macro, which enables non-linear performance which allows it to match extremely long tokens. The use of REJECT is discouraged by the Flex manual and thus not enabled by default. 

The scanner which Flex generates does not by default allow reentrancy. This means that the program can not safely be interrupted and then resumed later on.

\subsubsubsection{Jflex:}
Jflex is based on Flex and focuses on speed and full Unicode support. It can be used as a standalone tool or together with the LALR parser generators Cup and BYacc/J \citep{Jflex}.

\subsubsubsection{Jlex:}
Based on Lex but used for Java \citep{Jlex}.

\subsubsection{Parser}
Parsertools generate a parser, based on a formal grammar from a lexer it checks for correct syntax and builds a data structure (Often in the form of a parse tree, abstract syntax tree or other hierarchical structure). 

\subsubsubsection{Yacc:}
Generates a LALR parser that checks the syntax based on an analytic grammar, written in a similar fashion to BNF. it Requires an external lexical analyzer, such as those generated by Lex or Flex. The output language is C \citep{Yacc}.

\subsubsubsection{Cup:}
Similar to Yacc, output language is in Java instead \citep{CUP}.

\subsubsection{Lexer and Parser Generators}
Combines the lexer and parser generator in one tool.

\subsubsubsection{SableCC:}
Using CFG (Context Free Grammar) written in EBNF (Extented Backus-Naur= Form SableCC generates a LALR(1) parser. The output languages are: C, C++, C\#, Java, OCaml or Python \citep{SableCC}.

\subsubsubsection{ANTLR:}
\textit{ANother Tool for Language Recognition} uses the CFG (Context Free Grammar) written in EBNF to generate an LL(*) parser. It has a wide variety of output languages, including, C, C++ and Java.
ANTLR can also make a tree parser and combined lexer-parser. Lexer rules are written with an upper-case first letter so that ANTLR can distinguish between lexer rules and parser rules \citep{ANTLRLexer}. 
%Those abstract syntax trees can be further processed with a tree parsers.

\subsubsubsection{JavaCC:}
JavaCC generates a parser from a formal grammar written in EBNF notation. The output is Java source code. JavaCC generates top-down parsers, which limits it to the LL(*) class of grammars (in particular, left recursion cannot be used). JavaCC also generates lexical analyzers in a fashion similar to Lex \citep{Javacc}. The tree builder that accompanies it, JJTree, constructs its trees from the bottom up \citep{JJTree}.

\subsubsection{Comparison Tables}
On table \ref{tab:ComparisonLexer} a comparison between the different lexers can be seen. It has been used in the discussion about how to make the lexer in this project.
\begin{table}[H]
\begin{tabular}{|l|c|c|}
\hline
\textbf{Name}	& \textbf{Lexer Algorithm}	& \textbf{Output language}	\\ \hline
Lex				& DFA						& C							\\ \hline
Flex			& DFA table driven			& C, C++					\\ \hline
Jflex			& DFA						& Java						\\ \hline
Jlex			& DFA						& Java						\\ \hline
\end{tabular}
\caption{Comparison between the different lexical analyzers.}
\label{tab:ComparisonLexer}
\end{table}

\begin{table}[H]
\begin{tabularx}{\textwidth}{|l|c|c|R|c|}
\hline
\textbf{Name} & \textbf{Parsing algorithm} & \textbf{Input notation} & \textbf{Output language} & \textbf{Lexer}		  \\ \hline
Yacc 	& LALR(1) & YACC & C																				  &	External  \\ \hline
Cup		& LALR(1) & EBNF & Java																				  &	External  \\ \hline
SableCC & LALR(1) & EBNF & C, C++, C\#, Java, OCaml,Python													  &	Generated \\ \hline
ANTLR 	& LL(*)   & EBNF & ActionScript, Ada95, C, C++, C\#, Java, JavaScript, Objective-C, Perl, Python, Ruby & Generated \\ \hline
JavaCC 	& LL(*)   & EBNF & Java, C++(beta)																	  &	Generated \\ \hline
\end{tabularx}
\caption{Comparison between the different parsers and  lexer-parser generators.}
\label{tab:ComparisonParser}
\end{table}

Based on the different lexer and parser attributes (seen table on \ref{tab:ComparisonLexer} and \ref{tab:ComparisonParser}) and compared to the expectations of this project, it has been decided that ANTLR fits the project best. The reason for this is that ANTLR uses the LL(*) parser algorithm. This fits the structure of the CFG grammar for this project. ANTLR's output language can be in Java, C or C++. Another possibility could be to write the lexer and parser by hand, but a tool made it possible to focus on other parts of the project. Additionally, it is easier to maintain the lexer and parser with a tool. When the grammar is changed, you can just generate a new lexer and parser with the tool. It has therefore been decided to use ANTLR for generating the lexer and parser in this project.