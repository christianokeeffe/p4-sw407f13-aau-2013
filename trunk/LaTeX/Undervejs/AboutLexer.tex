
\section{Lexical analyzer}
A lexical analyzer reads the input file, and returns a series of tokens based based on the input. More specifically it is the scanner in the lexical analyzer which does this. These tokens are matched by rules, usually described by regular expressions. An example of such grammar rules can be seen on \ref{tab:tokenspecification}. Formally a token consists of two parts: The token type, and the token value. As an example the IDENT token seen on \ref{tab:tokensexample} has the token type IDENT and the value 'c'. 

\begin{table}[H]
\begin{tabular}{|l|l|}
\hline
    	Terminal  	& Regular expression 	\\ \hline
    	dcl       	& "$[a-z]$"      			\\ 
    	assign    	& "="      				\\ 
    	digit     	& "$[0-9]^+$"   			\\ 
    	endassign 	& ";"      				\\
    	blank 		& $" "^+$					\\
    \hline
\end{tabular}
\caption{Sample token specification}
\label{tab:tokenspecification}
\end{table}
This specification of tokens, would be used by the scanner to determine how tokens looks, and thereby which text-elements are tokens. 

%\begin{code}[Simple example of code,simplecode]
%c = 42;
%\end{code}

For example the lines of code seen on \ref{code:simplecode} might be read as the tokens seen on figure \ref{tab:tokensexample}.
\begin{table}[H]
\begin{tabular}{|l|l|}
\hline
    Token     & Lexeme \\ \hline
    IDENT     & c      \\ 
    ASSIGN    & =      \\ 
    DIGIT     & 42     \\ 
    SEMICOLON & ;      \\
    \hline
\end{tabular}
\caption{Example of tokens}
\label{tab:tokensexample}
\end{table}
The scanner produces a stream of tokens, which is returned to the parser, which checks if the tokens conforms to the language-specification.